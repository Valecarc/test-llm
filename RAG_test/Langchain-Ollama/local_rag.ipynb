{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alarcon7a/Langchain-con-Ollama/blob/main/local_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a427e3b219ad4983",
      "metadata": {
        "id": "a427e3b219ad4983"
      },
      "outputs": [],
      "source": [
        "# pip install fastembed langchain langchain_community PyMuPDF chromadb "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "609696e2cbc36f00",
      "metadata": {
        "id": "609696e2cbc36f00"
      },
      "source": [
        "## Ollama from langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:48:25.727440Z",
          "start_time": "2024-05-07T04:48:03.117052Z"
        },
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import Ollama\n",
        "\n",
        "llm = Ollama(model=\"llama3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "818373ec",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hola! Soy LLaMA, un modelo de lenguaje artificialmente inteligente (AI) desarrollado por Meta AI. Mi función es entender y responder a preguntas o conversar con personas en forma natural, como si fuera una persona real. Me encanta aprender sobre diferentes temas y cultura, así que estoy aquí para escucharte y ayudarte de alguna manera. ¿De dónde eres?'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"Hola, quien eres?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3d74fb9c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'¡Claro!\\n\\nEl Databricks AI Security Framework (DASF) es un conjunto de herramientas y prácticas para ayudar a las organizaciones a implementar una seguridad efectiva en sus aplicaciones y servicios de inteligencia artificial (IA). Fue desarrollado por Databricks, una empresa líder en soluciones de análisis y procesamiento de datos basados en la nube.\\n\\nEl objetivo principal del DASF es proporcionar un marco sólido para garantizar la integridad y confidencialidad de los datos y sistemas de IA. Esto se logra mediante la implementación de controles de seguridad efectivos en cada nivel del proceso de desarrollo, ejecución y monitoreo de aplicaciones de IA.\\n\\nEl DASF consta de tres componentes clave:\\n\\n1. **Data Handling**: Establece políticas y procedimientos para el manejo seguro de datos, incluyendo la autenticación, autorización y acceso controlado a los datos.\\n2. **Model Training and Deployment**: Proporciona guías y herramientas para la capacitación y despliegue seguros de modelos de IA, incluyendo la evaluación de riesgos y la implementación de controles de versión y rollback.\\n3. **Runtime Security**: Ofrece una capa adicional de seguridad durante el ejecución de aplicaciones de IA, mediante la detección de anomalías, la prevención de ataques y la respuesta a incidentes.\\n\\nEl DASF también incluye prácticas recomendadas para la implementación efectiva de la seguridad en proyectos de IA, como:\\n\\n* La identificación y mitigación de riesgos de privacidad y seguridad\\n* La evaluación continua del rendimiento y la precisión de modelos de IA\\n* La documentación y el seguimiento de los cambios en las aplicaciones y sistemas de IA\\n\\nEn resumen, el Databricks AI Security Framework (DASF) es un enfoque integral para garantizar la seguridad y integridad de aplicaciones y servicios de IA. Ayuda a las organizaciones a implementar prácticas seguras y a reducir el riesgo de ataques y brechas de seguridad en su infraestructura de IA.\\n\\n¿Tienes alguna pregunta específica sobre el DASF o cómo implementarlo en tu proyecto?'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"puedes contarme algo acerca del Databricks AI Security Framework (DASF) \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "70392a3a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"What a great topic!\\n\\nAs of my knowledge cutoff in late 2023, I can provide some insights on the Databricks AI Security Framework (DASF). Please note that information might have changed since then.\\n\\n**What is Databricks AI Security Framework (DASF)?**\\n\\nThe Databricks AI Security Framework is an open-source framework designed to help organizations build and maintain trust in their AI systems. It's a comprehensive framework for securing AI pipelines, ensuring the reliability and integrity of AI-driven decision-making processes. The goal is to create transparency, explainability, and accountability throughout the AI development lifecycle.\\n\\n**Novedades en 2024 (2024 Updates)**\\n\\nAs of my knowledge cutoff, here are some potential updates you might expect in 2024:\\n\\n1. **Enhanced Explainability**: Databricks may focus on improving the explainability aspects of the framework to better enable organizations to understand AI-driven decisions and outcomes.\\n2. **Increased Transparency**: Expect more transparency features within the framework to ensure that AI systems are fair, unbiased, and reliable.\\n3. **Advanced Risk Management**: The 2024 updates might include enhanced risk management capabilities to identify and mitigate potential risks associated with AI-powered decision-making processes.\\n4. **Integration with Other Security Tools**: Databricks may strive to integrate DASF with other security tools and frameworks to provide a more comprehensive approach to AI security.\\n5. **Expanded Compliance Support**: The framework could expand its support for compliance standards, such as GDPR, HIPAA, and CCPA, to help organizations meet regulatory requirements.\\n6. **AI Governance**: Expect updates on AI governance features within DASF to ensure responsible AI development, deployment, and maintenance practices.\\n7. **Improved Collaboration**: The 2024 updates might focus on improving collaboration and knowledge sharing between data scientists, developers, and security professionals to foster a culture of AI security.\\n\\nPlease note that these are just predictions based on my understanding of the framework's goals and industry trends. For the most up-to-date information, I recommend checking the Databricks website or attending relevant conferences and webinars in 2024.\\n\\nWould you like me to elaborate on any specific aspect of DASF or its potential updates?\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"puedes contarme que novedades hay respecto al Databricks AI Security Framework (DASF) en 2024 \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f6c4046251edad",
      "metadata": {
        "id": "2f6c4046251edad"
      },
      "source": [
        "## RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37c2e425161bbe10",
      "metadata": {
        "id": "37c2e425161bbe10"
      },
      "source": [
        "### Load Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e535977811b3eaaa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:48:26.105535Z",
          "start_time": "2024-05-07T04:48:25.729887Z"
        },
        "id": "e535977811b3eaaa"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader(\"../../Info_data/databricks-whitepaper.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "aed45119c2090e4f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:48:33.783299Z",
          "start_time": "2024-05-07T04:48:26.107317Z"
        },
        "id": "aed45119c2090e4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pdf = loader.load()\n",
        "len(data_pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "46ce479e22ee5646",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:48:33.789542Z",
          "start_time": "2024-05-07T04:48:33.785472Z"
        },
        "id": "46ce479e22ee5646"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='DATABRICKS \\nAI SECURITY \\nFRAMEWORK \\n(DASF) \\nVERSION 1.0\\nTable of Contents\\nExecutive Summary \\t\\n 3\\n1   Introduction \\t\\n 5\\n1.1 \\t\\nIntended audience \\t\\n 6\\n1.2 \\t\\nHow to use this document \\t\\n 7\\n2   Risks in AI System Components \\t\\n 9\\n2.1 \\t\\nRaw Data \\t\\n 13\\n2.2 \\t\\nData Prep \\t\\n 16\\n2.3 \\t\\nDatasets \\t\\n 19\\n2.4 \\t\\nData Catalog Governance \\t\\n 20\\n2.5 \\t\\nMachine Learning Algorithms \\t\\n 22\\n2.6 \\t\\nEvaluation \\t\\n 24\\n2.7 \\t\\nMachine Learning Models \\t\\n 25\\n2.8 \\t\\nModel Management \\t\\n 27\\n2.9 \\t\\nModel Serving and Inference Requests \\t\\n 29\\n2.10 \\t Model Serving and Inference Response \\t\\n 37\\n2.11 \\t\\nMachine Learning Operations (MLOps) \\t\\n 41\\n2.12 \\t Data and AI Platform Security \\t\\n 42\\n3   Understanding Databricks Data Intelligence Platform AI Risk Mitigation Controls \\t\\n 44\\n3.1 \\t\\nThe Databricks Data Intelligence Platform \\t\\n 44\\nMosaic AI \\t\\n 46\\nDatabricks Unity Catalog \\t\\n 47\\nDatabricks Platform Architecture \\t\\n 48\\nDatabricks Platform Security \\t\\n 49\\n3.2 \\t Databricks AI Risk Mitigation Controls \\t\\n 50\\n4   Conclusion \\t\\n 66\\n5   Resources and Further Reading \\t\\n 68\\n6   Acknowledgments \\t\\n 70\\n7   Appendix: Glossary \\t\\n 72\\n8   License \\t\\n 84\\nAuthors \\t\\n \\nOmar Khawaja\\nVice President and Field Chief \\nInformation Security Officer\\nArun Pamulapati\\nSenior Staff Security Field Engineer\\nKelly Albano\\nProduct Marketing Manager\\n', metadata={'source': '../../Info_data/databricks-whitepaper.pdf', 'file_path': '../../Info_data/databricks-whitepaper.pdf', 'page': 1, 'total_pages': 84, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 19.2 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': \"D:20240318124324-07'00'\", 'modDate': \"D:20240318124403-07'00'\", 'trapped': ''})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pdf[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "29127546585240e1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:48:33.884111Z",
          "start_time": "2024-05-07T04:48:33.790718Z"
        },
        "id": "29127546585240e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "139"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=500)\n",
        "docs = text_splitter.split_documents(data_pdf)\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "290fafdb4213c62b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:48:33.889526Z",
          "start_time": "2024-05-07T04:48:33.885436Z"
        },
        "id": "290fafdb4213c62b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='3\\nDATABRICKS \\nAI SECURITY \\nFRAMEWORK \\n(DASF) \\nVERSION 1.0\\nExecutive Summary\\nMachine learning (ML) and generative AI (GenAI) are transforming the \\nfuture of work by enhancing innovation, competitiveness and employee \\nproductivity. However, organizations are grappling with the dual challenge \\nof leveraging artificial intelligence (AI) technologies for opportunities while \\nmanaging potential security and privacy risks, such as data breaches and \\nregulatory compliance.\\nAdopting AI also raises regulatory considerations, exemplified by President Joe Biden’s \\nExecutive Order (E.O. 14110) and NIST’s AI Risk Management Framework, underlining the \\nimportance of responsible governance and oversight. The evolving legal and regulatory \\nlandscape, combined with uncertainties around ownership accountability, leaves data, IT \\nand security leaders navigating how to effectively harness generative AI for organizational \\nbenefits while addressing perceived risks.\\nThe Databricks Security team created the Databricks AI Security Framework (DASF) \\nto address the evolving risks associated with the widespread integration of AI globally. \\nUnlike approaches that focus solely on securing models or endpoints, the DASF adopts a \\ncomprehensive strategy to mitigate cyber risks in AI systems. Based on real-world evidence \\nindicating that attackers employ simple tactics to compromise ML-driven systems, the \\nDASF offers actionable defensive control recommendations. These recommendations can \\nbe updated as new risks emerge and additional controls become available. The framework’s \\ndevelopment involved a thorough review of multiple risk management frameworks, \\nrecommendations, whitepapers, policies and AI security acts.\\nThe DASF is designed for collaboration between business, IT, data, AI and security teams \\nthroughout the AI lifecycle. It addresses the evolving nature of data science from a \\nresearch-oriented to a project-based discipline, facilitating structured conversations on \\nsecurity threats and mitigations without needing deep expertise crossover. We believe \\nthe document will be valuable to security teams, ML practitioners and governance officers, \\nproviding insights into how ML impacts system security, applying security engineering \\nprinciples to ML, and offering a detailed guide for understanding the security and \\ncompliance of specific ML systems.\\n⟶ Executive\\nSummary\\nIntroduction\\nRisks in AI System \\nComponents\\nUnderstanding \\nDatabricks Data \\nIntelligence Platform \\nAI Risk Mitigation \\nControls\\nConclusion\\nResources and \\nFurther Reading\\nAcknowledgments\\nAppendix: \\n\\nGlossary\\nLicense', metadata={'source': '../../Info_data/databricks-whitepaper.pdf', 'file_path': '../../Info_data/databricks-whitepaper.pdf', 'page': 2, 'total_pages': 84, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 19.2 (Macintosh)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': \"D:20240318124324-07'00'\", 'modDate': \"D:20240318124403-07'00'\", 'trapped': ''})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fbc2f7d236e5f652",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:48:35.263166Z",
          "start_time": "2024-05-07T04:48:33.906941Z"
        },
        "id": "fbc2f7d236e5f652"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/linuxlab/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 15947.92it/s]\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
        "embed_model = FastEmbedEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b8690559a38ae72c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:50:50.200097Z",
          "start_time": "2024-05-07T04:49:42.943717Z"
        },
        "id": "b8690559a38ae72c"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "vs = Chroma.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embed_model,\n",
        "    persist_directory=\"vector_databricks\",  # Local mode with in-memory storage only\n",
        "    collection_name=\"DASF\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "491315bd48fe2b3a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:51:59.633151Z",
          "start_time": "2024-05-07T04:51:59.615279Z"
        },
        "id": "491315bd48fe2b3a"
      },
      "outputs": [],
      "source": [
        "vectorstore = Chroma(embedding_function=embed_model,\n",
        "                     persist_directory=\"vector_databricks\",\n",
        "                     collection_name=\"DASF\")\n",
        "retriever=vectorstore.as_retriever(search_kwargs={'k': 4})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "be4ecf951a8e7dba",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:58:57.064376Z",
          "start_time": "2024-05-07T04:58:57.060843Z"
        },
        "id": "be4ecf951a8e7dba"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "custom_prompt_template = \"\"\"Usa la siguiente información para responder a las preguntas del usuario.\n",
        "Si no sabes la respuesta, simplemente di que no lo sabes, no intentes inventar algun tipo de respuesta.\n",
        "\n",
        "Contexto: {context}\n",
        "Pregunta: {question}\n",
        "\n",
        "Responde siempre en español y solo devuelve la respuesta útil a continuación y nada más.\n",
        "Respuesta útil:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(template=custom_prompt_template,\n",
        "                        input_variables=['context', 'question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d9bb4df68390ea68",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:58:59.535953Z",
          "start_time": "2024-05-07T04:58:59.532673Z"
        },
        "id": "d9bb4df68390ea68"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=retriever,\n",
        "                                 return_source_documents=True,\n",
        "                                 chain_type_kwargs={\"prompt\": prompt})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "aff152852bbbcae",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:54:55.348321Z",
          "start_time": "2024-05-07T04:54:10.731031Z"
        },
        "id": "aff152852bbbcae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Los temas más relevantes presentados en el Databricks AI Security Framework (DASF) son:\\n\\n* Componentes de un sistema de inteligencia artificial (AI): raw data, data prep, datasets, data and AI governance, machine learning algorithms, evaluation, machine learning models, model management, model serving and inference, inference response, machine learning operations y data and AI platform security.\\n* Riesgos técnicos asociados a estos componentes: 55 riesgos técnicos identificados que pueden surgir en la implementación de sistemas de inteligencia artificial.\\n* Control de riesgos: recomendaciones para mitigar los riesgos técnicos identificados, incluyendo el papel compartido entre Databricks y la organización.\\n\\nEn resumen, el DASF se centra en proporcionar una guía práctica para desarrollar, implementar y mantener modelos de inteligencia artificial de manera segura y eficaz.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = qa.invoke({\"query\": \"Cuales son los temas mas reelevantes presentados en el Databricks AI Security Framework (DASF) en 2024 ?\"})\n",
        "response['result']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9bf74e1c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'La recomendación más relevante según el archivo DASF (Data and AI Security Framework) en 2024 es aprender sobre **AI Risk Mitigation Controls**. Este tema es crucial para garantizar la seguridad de los sistemas de aprendizaje automático y proteger contra ataques y riesgos como jailbreaking, black-box attacks, infer training data membership y source code control attack.\\n\\nEs importante mencionar que el DASF 2024 proporciona una amplia gama de recomendaciones y controles para mitigar riesgos en diferentes áreas relacionadas con la inteligencia artificial, incluyendo model serving, inference requests, model operations y más. Sin embargo, aprendiendo sobre AI Risk Mitigation Controls es fundamental para proteger contra los peligros mencionados anteriormente.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = qa.invoke({\"query\": \"De acuerdo al archivo de DASF en 2024 que tema me recomendarias apdrender ? que parece ser lo mas reelevante ?\"})\n",
        "response['result']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9bc6ff48",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(23, '../../Info_data/databricks-whitepaper.pdf'),\n",
              " (39, '../../Info_data/databricks-whitepaper.pdf'),\n",
              " (32, '../../Info_data/databricks-whitepaper.pdf'),\n",
              " (25, '../../Info_data/databricks-whitepaper.pdf')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metadata = []\n",
        "for _ in response['source_documents']:\n",
        "    metadata.append((_.metadata['page'], _.metadata['file_path']))\n",
        "metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c747508f1da46dc3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T04:59:12.673266Z",
          "start_time": "2024-05-07T04:59:04.476662Z"
        },
        "id": "c747508f1da46dc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'El objetivo principal del DATABRICKS AI SECURITY FRAMEWORK (DASF) en 2024 es proteger los modelos de aprendizaje automático (ML) y lenguaje natural grande (LLM) de ataques y riesgos, garantizando la seguridad y integridad de la información y los procesos que involucran el uso de modelos ML/LLM.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = qa.invoke({\"query\": \"cual es el objetivo principal para el DASF en 2024 ?\"})\n",
        "response['result']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b1ebae3dbea446df",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-07T05:00:07.923439Z",
          "start_time": "2024-05-07T05:00:07.917548Z"
        },
        "id": "b1ebae3dbea446df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(23, '../../Info_data/databricks-whitepaper.pdf'),\n",
              " (25, '../../Info_data/databricks-whitepaper.pdf'),\n",
              " (16, '../../Info_data/databricks-whitepaper.pdf'),\n",
              " (39, '../../Info_data/databricks-whitepaper.pdf')]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metadata = []\n",
        "for _ in response['source_documents']:\n",
        "    metadata.append((_.metadata['page'], _.metadata['file_path']))\n",
        "metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e789060a",
      "metadata": {},
      "source": [
        "# Integracion con Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "107cd711",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iniciar una interfaz\n",
        "import gradio as gr \n",
        "\n",
        "def Pregunta(question):\n",
        "    response = qa.invoke(qa.invoke({\"query\": question}))\n",
        "    return response['result']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "05297143",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "titulo= \"Asesor - DATABRICKS AI SECURITY FRAMEWORK (DASF)\"\n",
        "descripcion= \"Intento de RAG con DASF 2024 pdf\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=Pregunta,\n",
        "    inputs=gr.Textbox(lines=10, placeholder=\"Cual es tu pregunta:\"),\n",
        "    outputs=\"text\",\n",
        "    title=titulo,\n",
        "    description=descripcion\n",
        ")\n",
        "\n",
        "demo.launch()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "10997697",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing server running on port: 7862\n"
          ]
        }
      ],
      "source": [
        "demo.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
